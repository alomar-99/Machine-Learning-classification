{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Glct7opiQer"
      },
      "source": [
        "# **Package imports**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dayc77WcmLdL"
      },
      "source": [
        "**Installing dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shLyiE_7jOIC",
        "outputId": "136a442d-df5e-4031-858c-cfd87a1b3aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.8/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.9.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.23.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.5->category_encoders) (2022.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dython in /usr/local/lib/python3.8/dist-packages (0.7.3)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.8/dist-packages (from dython) (0.12.1)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.8/dist-packages (from dython) (5.9.4)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.8/dist-packages (from dython) (0.3.7)\n",
            "Requirement already satisfied: pandas>=1.4.2 in /usr/local/lib/python3.8/dist-packages (from dython) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.8/dist-packages (from dython) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from dython) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from dython) (1.9.3)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.8/dist-packages (from dython) (3.6.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (4.38.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (1.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.3->dython) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.2->dython) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->dython) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->dython) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->dython) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install category_encoders\n",
        "!{sys.executable} -m pip install dython\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "xCIisWBQiQes"
      },
      "outputs": [],
      "source": [
        "#general\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "from dython.nominal import associations\n",
        "\n",
        "#useful modules\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, matthews_corrcoef as MCC\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#classifiers\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pda6cFY8iQeu"
      },
      "source": [
        "# **Data preparation & Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "t0z9uB5AiQev"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Dataset-vf.csv')\n",
        "\n",
        "X = df[df.columns[:-1]]\n",
        "Y = df[\"Y\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5TDAuSfiQev"
      },
      "source": [
        "**Data Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIODrHfJiQew",
        "outputId": "e5505fe9-53d9-4e07-abe3-086dc8a739ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset has 6374 samples and 15 features per sample\n",
            "\n",
            "The dataset has 7 classes and they are as follow: ['Melon' 'Carrot' 'Orange' 'Apple' 'Berry' 'Mango' 'Peach']\n",
            "\n",
            "Dataset distribution:\n",
            "{'Apple': 1275, 'Berry': 1250, 'Carrot': 1620, 'Mango': 250, 'Melon': 1571, 'Orange': 100, 'Peach': 308}\n",
            "\n",
            "Column: X1 has this number of missing values = 0\n",
            "Column: X2 has this number of missing values = 627\n",
            "Column: X3 has this number of missing values = 0\n",
            "Column: X4 has this number of missing values = 0\n",
            "Column: X5 has this number of missing values = 0\n",
            "Column: X6 has this number of missing values = 0\n",
            "Column: X7 has this number of missing values = 0\n",
            "Column: X8 has this number of missing values = 0\n",
            "Column: X9 has this number of missing values = 0\n",
            "Column: X10 has this number of missing values = 0\n",
            "Column: X11 has this number of missing values = 0\n",
            "Column: X12 has this number of missing values = 0\n",
            "Column: X13 has this number of missing values = 0\n",
            "Column: X14 has this number of missing values = 0\n",
            "Column: X15 has this number of missing values = 5743\n",
            "Column: Y has this number of missing values = 0\n",
            "\n",
            "Feature: X1 Stats, \n",
            "      Mean = 2635.86, \n",
            "      Std = 394.72, \n",
            "      Max = 3675, \n",
            "      Min = 1863\n",
            "Feature: X2 Stats, \n",
            "      Mean = 153.24, \n",
            "      Std = 105.62, \n",
            "      Max = 360.0, \n",
            "      Min = 0.0\n",
            "Feature: X3 Stats, \n",
            "      Mean = 17.06, \n",
            "      Std = 9.01, \n",
            "      Max = 52, \n",
            "      Min = 0\n",
            "Feature: X4 Stats, \n",
            "      Mean = 191.49, \n",
            "      Std = 177.84, \n",
            "      Max = 1129, \n",
            "      Min = 0\n",
            "Feature: X5 Stats, \n",
            "      Mean = 47.86, \n",
            "      Std = 57.64, \n",
            "      Max = 334, \n",
            "      Min = -134\n",
            "Feature: X6 Stats, \n",
            "      Mean = 1515.54, \n",
            "      Std = 1281.42, \n",
            "      Max = 6890, \n",
            "      Min = 0\n",
            "Feature: X7 Stats, \n",
            "      Mean = 215.19, \n",
            "      Std = 31.64, \n",
            "      Max = 254, \n",
            "      Min = 0\n",
            "Feature: X8 Stats, \n",
            "      Mean = 218.02, \n",
            "      Std = 23.85, \n",
            "      Max = 254, \n",
            "      Min = 99\n",
            "Feature: X9 Stats, \n",
            "      Mean = 130.3, \n",
            "      Std = 49.01, \n",
            "      Max = 248, \n",
            "      Min = 0\n",
            "Feature: X10 Stats, \n",
            "      Mean = 1425.02, \n",
            "      Std = 1109.52, \n",
            "      Max = 6853, \n",
            "      Min = 30\n",
            "Feature: X11 Stats, \n",
            "      Mean = 0.49, \n",
            "      Std = 0.29, \n",
            "      Max = 1.0, \n",
            "      Min = 0.0\n",
            "Feature: X12 Stats, \n",
            "      Mean = 6.79, \n",
            "      Std = 573.93, \n",
            "      Max = 1000, \n",
            "      Min = -1000\n"
          ]
        }
      ],
      "source": [
        "print(\"The dataset has {} samples and {} features per sample\\n\".format(df.shape[0], df.shape[1]-1))\n",
        "\n",
        "print(\"The dataset has {} classes and they are as follow: {}\\n\".format(len(df['Y'].unique()), df['Y'].unique()))\n",
        "\n",
        "class_labels, class_counts = np.unique(df['Y'], return_counts=True)\n",
        "print(\"Dataset distribution:\")\n",
        "print(dict(zip(class_labels, class_counts)))\n",
        "print('')\n",
        "\n",
        "def countMissingVals(X):\n",
        "  for col in X.columns:\n",
        "      nanCount = X[f'{col}'].isnull().sum()\n",
        "      print(\"Column: {} has this number of missing values = {}\".format(col, nanCount))\n",
        "\n",
        "countMissingVals(df)\n",
        "print('')\n",
        "def dataStatistics(X):\n",
        "  for col in X.columns:\n",
        "    if X[col].dtype == \"object\":\n",
        "      pass\n",
        "    else:\n",
        "      print(\"\"\"Feature: {} Stats, \n",
        "      Mean = {}, \n",
        "      Std = {}, \n",
        "      Max = {}, \n",
        "      Min = {}\"\"\".format(col, round(df[col].mean(), 2), round(df[col].std(), 2), df[col].max(), df[col].min()))\n",
        "      \n",
        "dataStatistics(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waNlz4QfiQex"
      },
      "source": [
        "**Categorical data Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKmxoNQsiQey",
        "outputId": "0778c80e-77ef-4101-d33f-7286ed702404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of values = 4, [' FC11' ' FC14' ' FC13' ' FC12']\n",
            "Num of values = 32, [' CA49' ' CA50' ' CA26' ' CA32' ' CA38' ' CA42' ' CA37' ' CA23' ' CA24'\n",
            " ' CA21' ' CA43' ' CA22' ' CA36' ' CA33' ' CA44' ' CA59' ' CA30' ' CA40'\n",
            " ' CA51' ' CA52' ' CA31' ' CA58' ' CA25' ' CA39' ' CA53' ' CA60' ' CA46'\n",
            " ' CA54' ' CA34' ' CA41' ' CA48' ' CA55']\n"
          ]
        }
      ],
      "source": [
        "X = X.drop(\"X15\", axis=1)\n",
        "\n",
        "x13 = X[\"X13\"].unique()\n",
        "x14 = X[\"X14\"].unique()\n",
        "\n",
        "print(\"Num of values = {}, {}\".format(len(x13), x13))\n",
        "print(\"Num of values = {}, {}\".format(len(x14), x14))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qxq0E9S3rCv"
      },
      "source": [
        "**Data correlation analysis with categorical data useing Dython library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "inEE0WRi3kym",
        "outputId": "0caa8493-88ca-4779-cdbf-f5e6ca4ad69c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d3200a94-01e6-4124-af1a-b50491221623\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004343</td>\n",
              "      <td>-0.333203</td>\n",
              "      <td>0.329017</td>\n",
              "      <td>-0.002311</td>\n",
              "      <td>0.606769</td>\n",
              "      <td>0.072518</td>\n",
              "      <td>0.229464</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>0.463866</td>\n",
              "      <td>0.001618</td>\n",
              "      <td>-0.002352</td>\n",
              "      <td>0.874781</td>\n",
              "      <td>0.900729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X2</th>\n",
              "      <td>0.004343</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006776</td>\n",
              "      <td>0.015085</td>\n",
              "      <td>0.014722</td>\n",
              "      <td>0.071822</td>\n",
              "      <td>-0.508053</td>\n",
              "      <td>0.293633</td>\n",
              "      <td>0.542223</td>\n",
              "      <td>-0.045059</td>\n",
              "      <td>-0.021234</td>\n",
              "      <td>-0.007682</td>\n",
              "      <td>0.156590</td>\n",
              "      <td>0.247661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X3</th>\n",
              "      <td>-0.333203</td>\n",
              "      <td>-0.006776</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.018341</td>\n",
              "      <td>0.363640</td>\n",
              "      <td>-0.327663</td>\n",
              "      <td>-0.134366</td>\n",
              "      <td>-0.656795</td>\n",
              "      <td>-0.401927</td>\n",
              "      <td>-0.235959</td>\n",
              "      <td>0.010468</td>\n",
              "      <td>0.005183</td>\n",
              "      <td>0.305414</td>\n",
              "      <td>0.620458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X4</th>\n",
              "      <td>0.329017</td>\n",
              "      <td>0.015085</td>\n",
              "      <td>0.018341</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.624466</td>\n",
              "      <td>0.130159</td>\n",
              "      <td>-0.019646</td>\n",
              "      <td>0.047840</td>\n",
              "      <td>0.038178</td>\n",
              "      <td>0.115299</td>\n",
              "      <td>-0.005063</td>\n",
              "      <td>-0.004866</td>\n",
              "      <td>0.255371</td>\n",
              "      <td>0.404052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X5</th>\n",
              "      <td>-0.002311</td>\n",
              "      <td>0.014722</td>\n",
              "      <td>0.363640</td>\n",
              "      <td>0.624466</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.113061</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>-0.213299</td>\n",
              "      <td>-0.131816</td>\n",
              "      <td>-0.089477</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>-0.009564</td>\n",
              "      <td>0.137424</td>\n",
              "      <td>0.408334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X6</th>\n",
              "      <td>0.606769</td>\n",
              "      <td>0.071822</td>\n",
              "      <td>-0.327663</td>\n",
              "      <td>0.130159</td>\n",
              "      <td>-0.113061</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.024238</td>\n",
              "      <td>0.267689</td>\n",
              "      <td>0.211251</td>\n",
              "      <td>0.445928</td>\n",
              "      <td>-0.002762</td>\n",
              "      <td>-0.005791</td>\n",
              "      <td>0.522569</td>\n",
              "      <td>0.634081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X7</th>\n",
              "      <td>0.072518</td>\n",
              "      <td>-0.508053</td>\n",
              "      <td>-0.134366</td>\n",
              "      <td>-0.019646</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>-0.024238</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.039172</td>\n",
              "      <td>-0.776999</td>\n",
              "      <td>0.064237</td>\n",
              "      <td>0.011532</td>\n",
              "      <td>0.016630</td>\n",
              "      <td>0.144763</td>\n",
              "      <td>0.557979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X8</th>\n",
              "      <td>0.229464</td>\n",
              "      <td>0.293633</td>\n",
              "      <td>-0.656795</td>\n",
              "      <td>0.047840</td>\n",
              "      <td>-0.213299</td>\n",
              "      <td>0.267689</td>\n",
              "      <td>-0.039172</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.637684</td>\n",
              "      <td>0.122884</td>\n",
              "      <td>-0.034126</td>\n",
              "      <td>0.001968</td>\n",
              "      <td>0.282122</td>\n",
              "      <td>0.488182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X9</th>\n",
              "      <td>0.122600</td>\n",
              "      <td>0.542223</td>\n",
              "      <td>-0.401927</td>\n",
              "      <td>0.038178</td>\n",
              "      <td>-0.131816</td>\n",
              "      <td>0.211251</td>\n",
              "      <td>-0.776999</td>\n",
              "      <td>0.637684</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.054301</td>\n",
              "      <td>-0.028194</td>\n",
              "      <td>-0.011236</td>\n",
              "      <td>0.216832</td>\n",
              "      <td>0.547694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X10</th>\n",
              "      <td>0.463866</td>\n",
              "      <td>-0.045059</td>\n",
              "      <td>-0.235959</td>\n",
              "      <td>0.115299</td>\n",
              "      <td>-0.089477</td>\n",
              "      <td>0.445928</td>\n",
              "      <td>0.064237</td>\n",
              "      <td>0.122884</td>\n",
              "      <td>0.054301</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.012534</td>\n",
              "      <td>-0.004848</td>\n",
              "      <td>0.566034</td>\n",
              "      <td>0.633078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X11</th>\n",
              "      <td>0.001618</td>\n",
              "      <td>-0.021234</td>\n",
              "      <td>0.010468</td>\n",
              "      <td>-0.005063</td>\n",
              "      <td>-0.004616</td>\n",
              "      <td>-0.002762</td>\n",
              "      <td>0.011532</td>\n",
              "      <td>-0.034126</td>\n",
              "      <td>-0.028194</td>\n",
              "      <td>0.012534</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010958</td>\n",
              "      <td>0.038840</td>\n",
              "      <td>0.074812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X12</th>\n",
              "      <td>-0.002352</td>\n",
              "      <td>-0.007682</td>\n",
              "      <td>0.005183</td>\n",
              "      <td>-0.004866</td>\n",
              "      <td>-0.009564</td>\n",
              "      <td>-0.005791</td>\n",
              "      <td>0.016630</td>\n",
              "      <td>0.001968</td>\n",
              "      <td>-0.011236</td>\n",
              "      <td>-0.004848</td>\n",
              "      <td>0.010958</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.017128</td>\n",
              "      <td>0.062870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X13</th>\n",
              "      <td>0.874781</td>\n",
              "      <td>0.156590</td>\n",
              "      <td>0.305414</td>\n",
              "      <td>0.255371</td>\n",
              "      <td>0.137424</td>\n",
              "      <td>0.522569</td>\n",
              "      <td>0.144763</td>\n",
              "      <td>0.282122</td>\n",
              "      <td>0.216832</td>\n",
              "      <td>0.566034</td>\n",
              "      <td>0.038840</td>\n",
              "      <td>0.017128</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.712772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X14</th>\n",
              "      <td>0.900729</td>\n",
              "      <td>0.247661</td>\n",
              "      <td>0.620458</td>\n",
              "      <td>0.404052</td>\n",
              "      <td>0.408334</td>\n",
              "      <td>0.634081</td>\n",
              "      <td>0.557979</td>\n",
              "      <td>0.488182</td>\n",
              "      <td>0.547694</td>\n",
              "      <td>0.633078</td>\n",
              "      <td>0.074812</td>\n",
              "      <td>0.062870</td>\n",
              "      <td>0.712772</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3200a94-01e6-4124-af1a-b50491221623')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3200a94-01e6-4124-af1a-b50491221623 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3200a94-01e6-4124-af1a-b50491221623');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           X1        X2        X3        X4        X5        X6        X7  \\\n",
              "X1   1.000000  0.004343 -0.333203  0.329017 -0.002311  0.606769  0.072518   \n",
              "X2   0.004343  1.000000 -0.006776  0.015085  0.014722  0.071822 -0.508053   \n",
              "X3  -0.333203 -0.006776  1.000000  0.018341  0.363640 -0.327663 -0.134366   \n",
              "X4   0.329017  0.015085  0.018341  1.000000  0.624466  0.130159 -0.019646   \n",
              "X5  -0.002311  0.014722  0.363640  0.624466  1.000000 -0.113061 -0.050173   \n",
              "X6   0.606769  0.071822 -0.327663  0.130159 -0.113061  1.000000 -0.024238   \n",
              "X7   0.072518 -0.508053 -0.134366 -0.019646 -0.050173 -0.024238  1.000000   \n",
              "X8   0.229464  0.293633 -0.656795  0.047840 -0.213299  0.267689 -0.039172   \n",
              "X9   0.122600  0.542223 -0.401927  0.038178 -0.131816  0.211251 -0.776999   \n",
              "X10  0.463866 -0.045059 -0.235959  0.115299 -0.089477  0.445928  0.064237   \n",
              "X11  0.001618 -0.021234  0.010468 -0.005063 -0.004616 -0.002762  0.011532   \n",
              "X12 -0.002352 -0.007682  0.005183 -0.004866 -0.009564 -0.005791  0.016630   \n",
              "X13  0.874781  0.156590  0.305414  0.255371  0.137424  0.522569  0.144763   \n",
              "X14  0.900729  0.247661  0.620458  0.404052  0.408334  0.634081  0.557979   \n",
              "\n",
              "           X8        X9       X10       X11       X12       X13       X14  \n",
              "X1   0.229464  0.122600  0.463866  0.001618 -0.002352  0.874781  0.900729  \n",
              "X2   0.293633  0.542223 -0.045059 -0.021234 -0.007682  0.156590  0.247661  \n",
              "X3  -0.656795 -0.401927 -0.235959  0.010468  0.005183  0.305414  0.620458  \n",
              "X4   0.047840  0.038178  0.115299 -0.005063 -0.004866  0.255371  0.404052  \n",
              "X5  -0.213299 -0.131816 -0.089477 -0.004616 -0.009564  0.137424  0.408334  \n",
              "X6   0.267689  0.211251  0.445928 -0.002762 -0.005791  0.522569  0.634081  \n",
              "X7  -0.039172 -0.776999  0.064237  0.011532  0.016630  0.144763  0.557979  \n",
              "X8   1.000000  0.637684  0.122884 -0.034126  0.001968  0.282122  0.488182  \n",
              "X9   0.637684  1.000000  0.054301 -0.028194 -0.011236  0.216832  0.547694  \n",
              "X10  0.122884  0.054301  1.000000  0.012534 -0.004848  0.566034  0.633078  \n",
              "X11 -0.034126 -0.028194  0.012534  1.000000  0.010958  0.038840  0.074812  \n",
              "X12  0.001968 -0.011236 -0.004848  0.010958  1.000000  0.017128  0.062870  \n",
              "X13  0.282122  0.216832  0.566034  0.038840  0.017128  1.000000  0.712772  \n",
              "X14  0.488182  0.547694  0.633078  0.074812  0.062870  0.712772  1.000000  "
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "complete_correlation = associations(X, nominal_columns='auto', numerical_columns=None, \n",
        "             mark_columns=False, nom_nom_assoc='cramer', num_num_assoc='pearson', \n",
        "             cramers_v_bias_correction=True, nan_strategy='replace', nan_replace_value=0, \n",
        "             ax=None, figsize=None, annot=True, fmt='.2f', cmap=None, sv_color='silver', cbar=True, vmax=1.0, \n",
        "             vmin=None, plot=True, compute_only=True, clustering=False)\n",
        "\n",
        "df_complete_corr = complete_correlation['corr']\n",
        "df_complete_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go8CVjEiiQe0"
      },
      "source": [
        "**Encoding Categorical data using One Hot encoding & Binary encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1lqugZFEiQe0",
        "outputId": "4154e4d3-5542-47db-f4d2-fe7ca824b1c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33ad8e3e-d0da-40d9-90e3-1565a1b3f6dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X13_ FC11</th>\n",
              "      <th>X13_ FC12</th>\n",
              "      <th>X13_ FC13</th>\n",
              "      <th>X13_ FC14</th>\n",
              "      <th>X14_0</th>\n",
              "      <th>X14_1</th>\n",
              "      <th>X14_2</th>\n",
              "      <th>X14_3</th>\n",
              "      <th>X14_4</th>\n",
              "      <th>X14_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2709</td>\n",
              "      <td>59.0</td>\n",
              "      <td>11</td>\n",
              "      <td>120</td>\n",
              "      <td>43</td>\n",
              "      <td>150</td>\n",
              "      <td>228</td>\n",
              "      <td>217</td>\n",
              "      <td>120</td>\n",
              "      <td>2114</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2802</td>\n",
              "      <td>54.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>693</td>\n",
              "      <td>224</td>\n",
              "      <td>225</td>\n",
              "      <td>136</td>\n",
              "      <td>162</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2325</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1260</td>\n",
              "      <td>215</td>\n",
              "      <td>213</td>\n",
              "      <td>133</td>\n",
              "      <td>162</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2837</td>\n",
              "      <td>112.0</td>\n",
              "      <td>8</td>\n",
              "      <td>272</td>\n",
              "      <td>16</td>\n",
              "      <td>3649</td>\n",
              "      <td>235</td>\n",
              "      <td>231</td>\n",
              "      <td>128</td>\n",
              "      <td>6221</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2509</td>\n",
              "      <td>59.0</td>\n",
              "      <td>7</td>\n",
              "      <td>134</td>\n",
              "      <td>10</td>\n",
              "      <td>900</td>\n",
              "      <td>226</td>\n",
              "      <td>226</td>\n",
              "      <td>134</td>\n",
              "      <td>5184</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6369</th>\n",
              "      <td>3101</td>\n",
              "      <td>67.0</td>\n",
              "      <td>6</td>\n",
              "      <td>170</td>\n",
              "      <td>1</td>\n",
              "      <td>824</td>\n",
              "      <td>227</td>\n",
              "      <td>228</td>\n",
              "      <td>135</td>\n",
              "      <td>1657</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6370</th>\n",
              "      <td>3050</td>\n",
              "      <td>139.0</td>\n",
              "      <td>13</td>\n",
              "      <td>30</td>\n",
              "      <td>-3</td>\n",
              "      <td>3127</td>\n",
              "      <td>240</td>\n",
              "      <td>235</td>\n",
              "      <td>123</td>\n",
              "      <td>5770</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6371</th>\n",
              "      <td>2080</td>\n",
              "      <td>106.0</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>582</td>\n",
              "      <td>252</td>\n",
              "      <td>202</td>\n",
              "      <td>64</td>\n",
              "      <td>108</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6372</th>\n",
              "      <td>3011</td>\n",
              "      <td>108.0</td>\n",
              "      <td>10</td>\n",
              "      <td>212</td>\n",
              "      <td>36</td>\n",
              "      <td>2912</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>122</td>\n",
              "      <td>6632</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6373</th>\n",
              "      <td>1980</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22</td>\n",
              "      <td>300</td>\n",
              "      <td>125</td>\n",
              "      <td>300</td>\n",
              "      <td>185</td>\n",
              "      <td>193</td>\n",
              "      <td>140</td>\n",
              "      <td>927</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6374 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ad8e3e-d0da-40d9-90e3-1565a1b3f6dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33ad8e3e-d0da-40d9-90e3-1565a1b3f6dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33ad8e3e-d0da-40d9-90e3-1565a1b3f6dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        X1     X2  X3   X4   X5    X6   X7   X8   X9   X10  ...  X13_ FC11  \\\n",
              "0     2709   59.0  11  120   43   150  228  217  120  2114  ...          1   \n",
              "1     2802   54.0   7    0    0   693  224  225  136   162  ...          1   \n",
              "2     2325   28.0  12    0    0  1260  215  213  133   162  ...          0   \n",
              "3     2837  112.0   8  272   16  3649  235  231  128  6221  ...          1   \n",
              "4     2509   59.0   7  134   10   900  226  226  134  5184  ...          1   \n",
              "...    ...    ...  ..  ...  ...   ...  ...  ...  ...   ...  ...        ...   \n",
              "6369  3101   67.0   6  170    1   824  227  228  135  1657  ...          1   \n",
              "6370  3050  139.0  13   30   -3  3127  240  235  123  5770  ...          1   \n",
              "6371  2080  106.0  24   30   12   582  252  202   64   108  ...          0   \n",
              "6372  3011  108.0  10  212   36  2912  237  229  122  6632  ...          1   \n",
              "6373  1980    3.0  22  300  125   300  185  193  140   927  ...          0   \n",
              "\n",
              "      X13_ FC12  X13_ FC13  X13_ FC14  X14_0  X14_1  X14_2  X14_3  X14_4  \\\n",
              "0             0          0          0      0      0      0      0      0   \n",
              "1             0          0          0      0      0      0      0      1   \n",
              "2             0          0          1      0      0      0      0      1   \n",
              "3             0          0          0      0      0      0      1      0   \n",
              "4             0          0          0      0      0      0      1      0   \n",
              "...         ...        ...        ...    ...    ...    ...    ...    ...   \n",
              "6369          0          0          0      0      0      1      0      1   \n",
              "6370          0          0          0      0      1      0      0      1   \n",
              "6371          0          0          1      0      0      1      0      0   \n",
              "6372          0          0          0      0      0      0      0      0   \n",
              "6373          0          0          1      0      0      1      0      1   \n",
              "\n",
              "      X14_5  \n",
              "0         1  \n",
              "1         0  \n",
              "2         1  \n",
              "3         0  \n",
              "4         1  \n",
              "...     ...  \n",
              "6369      1  \n",
              "6370      0  \n",
              "6371      0  \n",
              "6372      1  \n",
              "6373      0  \n",
              "\n",
              "[6374 rows x 22 columns]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def dealWithCatData(X, cols, method=\"OneHot\"):\n",
        "  if method == \"OneHot\":\n",
        "    newX = X.copy()\n",
        "    newX = pd.get_dummies(newX,columns=cols)\n",
        "    return newX\n",
        "  else:\n",
        "    newX = X.copy()\n",
        "    encoder = ce.BinaryEncoder(cols=cols)\n",
        "    result = encoder.fit_transform(newX[cols])\n",
        "    newX = newX.drop(cols, axis=1)\n",
        "    newX = pd.concat([newX, result], axis=1)\n",
        "    return newX\n",
        "X = dealWithCatData(X, [\"X13\"], method=\"OneHot\")\n",
        "X = dealWithCatData(X, [\"X14\"], method=\"Binary\")\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jQpPF4-iQe0"
      },
      "source": [
        "**Helper methods to deal with missing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Yyj0_0-0iQe1"
      },
      "outputs": [],
      "source": [
        "def replaceWithZeros(X, nan_cols):\n",
        "  clean_X_Z = X.copy()\n",
        "  for col in nan_cols:\n",
        "    clean_X_Z[col] = clean_X_Z[col].fillna(0)\n",
        "  return clean_X_Z\n",
        "\n",
        "def replaceWithMean(X, nan_cols):\n",
        "  clean_X_M = X.copy()\n",
        "  for col in nan_cols:\n",
        "    clean_X_M[col] = clean_X_M[col].fillna(round(clean_X_M[col].mean(), 2))\n",
        "  return clean_X_M\n",
        "\n",
        "def replaceWithDrop(X, nan_cols, drop=\"col\"):\n",
        "\n",
        "  if drop == \"col\":\n",
        "    clean_X_DC = X.copy()\n",
        "    for col in nan_cols:\n",
        "      clean_X_DC = clean_X_DC.drop(col, axis=1)\n",
        "    return clean_X_DC\n",
        "\n",
        "  else:\n",
        "    clean_X_DR = X.copy()\n",
        "    clean_X_DR = clean_X_DR.dropna()\n",
        "    return clean_X_DR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waip_T3hiQe1"
      },
      "source": [
        "**Dealing with missing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "KF09fR1_iQe2"
      },
      "outputs": [],
      "source": [
        "def cleanMissingData(X):\n",
        "  nan_cols = []\n",
        "  for col in X.columns:\n",
        "      nanCount = X[f'{col}'].isnull().sum()\n",
        "      if nanCount > 0:\n",
        "        nan_cols.append(col)\n",
        "\n",
        "  if len(nan_cols) > 0:\n",
        "    clean_X_Z = replaceWithZeros(X, nan_cols)             # clean_X_Z = a data frame cleaned by replacing the missing data by Zeros\n",
        "    clean_X_M = replaceWithMean(X, nan_cols)              # clean_X_M = a data frame cleaned by replacing the missing data by Mean\n",
        "    clean_X_DC = replaceWithDrop(X, nan_cols, drop=\"col\") # clean_X_DC = a data frame cleaned by Droping the Column with missing data\n",
        "    clean_X_DR = replaceWithDrop(X, nan_cols, drop=\"Row\") # clean_X_DR = a data frame cleaned by Droping the Rows with missing data\n",
        "\n",
        "  return clean_X_Z, clean_X_M, clean_X_DC, clean_X_DR\n",
        "clean_X_Z, clean_X_M, clean_X_DC, clean_X_DR = cleanMissingData(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26P73hOBiQe2"
      },
      "source": [
        "**Data Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "XxxAi_6fiQe2"
      },
      "outputs": [],
      "source": [
        "def scaleData(scaler, X_train, X_test, X_val):\n",
        "    scaler.fit(X_train)\n",
        "    scaler.transform(X_train)\n",
        "    scaler.transform(X_test)\n",
        "    scaler.transform(X_val)\n",
        "\n",
        "def scaleAll(X_train, X_test, X_val, scaler=\"MinMax\"):\n",
        "    scaleData(MinMaxScaler(),X_train, X_test, X_val) if scaler == \"MinMax\" else scaleData(StandardScaler(),X_train, X_test, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbS0GdfvVXeU"
      },
      "source": [
        "#### **Feature expansion:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "-kmfnllCViKE"
      },
      "outputs": [],
      "source": [
        "def expandFeatures(X_train, X_test, X_val, degree_val=2):\n",
        "  poly = PolynomialFeatures(degree_val, include_bias=False)\n",
        "  X_train_poly = poly.fit_transform(X_train) \n",
        "  X_test_poly = poly.fit_transform(X_test)\n",
        "  X_val_poly = poly.fit_transform(X_val)\n",
        "  return X_train_poly, X_test_poly, X_val_poly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Bw4zu_iQe3"
      },
      "source": [
        "**Splitting Data into Training (70%) & Validation (15%) & Testing (15%)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnPcEzwUiQe3",
        "outputId": "dde52e26-d9b7-4ffe-8f8a-e4ed1826f107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 22 features per sample before expand Features\n",
            "\n",
            " 22 features per sample after expand Features\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(clean_X_Z, Y, test_size =0.3, random_state=0, stratify=Y)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size =0.5, random_state=0, stratify=Y_test)\n",
        "\n",
        "print(\" {} features per sample before expand Features\\n\".format(X_train.shape[1]))\n",
        "d0 = X_train.shape[1]\n",
        "# X_train, X_test, X_val = expandFeatures(X_train, X_test, X_val, degree_val=3) #might slow the training process depending on the classifier (with a slight improvement on performance).\n",
        "d1 = (X_train.shape[1])\n",
        "print(\" {} features per sample after expand Features\\n\".format(X_train.shape[1]))\n",
        "scaleAll(X_train, X_test, X_val, scaler=\"Standard\")\n",
        "\n",
        "ratio = d0/d1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWbMMhqviQe3"
      },
      "source": [
        "## **Unsupervised learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JnVj1soiQe4"
      },
      "source": [
        "#### **Dimensionality Reduction:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "_84zSsyyiQe4"
      },
      "outputs": [],
      "source": [
        "def reduceX(X,ratio, min):\n",
        "    numberOfFeatures = X.shape[1]\n",
        "    n_components = round(ratio * numberOfFeatures)\n",
        "    n_components = max(n_components, min)\n",
        "    pca = PCA(n_components=n_components, whiten=True)\n",
        "    X = pca.fit(X).transform(X)\n",
        "    return X\n",
        "\n",
        "def reduceAll(X_train, X_test, X_val, ratio=0.25, min = 2):\n",
        "    return reduceX(X_train, ratio, min), reduceX(X_test, ratio, min), reduceX(X_val, ratio, min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAAfrdNgAQ3J"
      },
      "source": [
        "**reducing number of features using PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "t16IbDg_jULY"
      },
      "outputs": [],
      "source": [
        "#it did a great job reducing the feautures but we decided to disable it since it drops the performance significantly \n",
        "\n",
        "# print(f\"Number of features before the reduction = {X_train.shape[1]}\")\n",
        "# X_train, X_test, X_val = reduceAll(X_train, X_test, X_val, ratio=ratio)\n",
        "# print(f\"Number of features after the reduction = {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmjWEJCwiQe4"
      },
      "source": [
        "# **classification:**\n",
        "we will use the following classifiers in order:\n",
        "\n",
        "**1- Linear Classifiers:**\n",
        "\n",
        "    1. Logistic Regression.\n",
        "    2. SVM.\n",
        "\n",
        "**2- Non-Linear Classifiers:**\n",
        "\n",
        "    1. KNN.\n",
        "    2. Neural Network.\n",
        "    3. Decision Tree.\n",
        "\n",
        "**3- Ensembel Learning:**\n",
        "\n",
        "    1. Bagging.\n",
        "    2. Adaboost.\n",
        "    3. Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMFMXUvqiQe4"
      },
      "source": [
        "#### **helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "0h6h_ePriQe5"
      },
      "outputs": [],
      "source": [
        "def Gmean(testy,y_pred):\n",
        "    precision = precision_score(testy, y_pred, average='micro')\n",
        "    recall = recall_score(testy, y_pred, average='micro')\n",
        "    return np.product(np.power([precision, recall], [0.6,0.4])) #60% precision, 40% recall\n",
        "    \n",
        "\n",
        "def testModel(model, testx, testy):\n",
        "    measures = {}\n",
        "    y_pred = model.predict(testx)\n",
        "    measures[\"accuracy\"] = classification_report(testy,y_pred,output_dict=True)[\"accuracy\"]\n",
        "    measures[\"f1_macro\"] = f1_score(testy,y_pred, average=\"macro\")\n",
        "    measures[\"f1_weighted\"] = f1_score(testy,y_pred, average=\"weighted\")\n",
        "    measures[\"mcc\"]= MCC(testy,y_pred)\n",
        "    measures[\"gmean\"]= Gmean(testy,y_pred)\n",
        "    return measures\n",
        "\n",
        "def classify(model, trainx ,trainy, testx, testy):\n",
        "    model.fit(trainx, trainy)\n",
        "    return testModel(model, testx, testy)\n",
        "\n",
        "def displayResults(models:list,X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
        "    for measure in models:\n",
        "        result = testModel(models[measure][\"model\"], X_train, Y_train)[measure]\n",
        "        print(f\"{measure} on Training set= {round(result*100,2)}%\")\n",
        "\n",
        "        result = testModel(models[measure][\"model\"], X_val, Y_val)[measure]\n",
        "        print(f\"{measure} on validation set= {round(result*100,2)}%\")\n",
        "\n",
        "        result = testModel(models[measure][\"model\"], X_test, Y_test)[measure]\n",
        "        print(f\"{measure} on test set= {round(result*100,2)}%\\n\")\n",
        "\n",
        "def printModels(models:dict):\n",
        "    if type(models) is not dict:\n",
        "        print(f\"{models}\", end=\", \")\n",
        "    else:\n",
        "        for model in models: \n",
        "            print(f\"{model}: \",end = \"\")\n",
        "            printModels(models[model])\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-aDiPt4iQe5"
      },
      "source": [
        "## **Linear classifiers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRLPkHlYiQe5"
      },
      "source": [
        "### **1-Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "6xY1ojzxiQe5"
      },
      "outputs": [],
      "source": [
        "def initializeLogisticRegression():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"C\":0,\n",
        "                \"penalty\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"C\":0,\n",
        "                \"penalty\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"C\":0,\n",
        "                \"penalty\":0\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"C\":0,\n",
        "                \"penalty\":0\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"C\":0,\n",
        "                \"penalty\":0\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "\n",
        "def updateLogisticRegression(measures, bestModels, model, C, penalty):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"C\"] = C\n",
        "            bestModels[measureType][\"hyperparameters\"][\"penalty\"] = penalty\n",
        "    return bestModels\n",
        "\n",
        "def bestLogisticRegression(trainx, trainy, testx, testy, regularizations:list, CValues:list, num_iterations:int=1000):\n",
        "    bestModels = initializeLogisticRegression()\n",
        "    for penalty in regularizations:\n",
        "        for C in CValues:\n",
        "            model = LogisticRegression(penalty = penalty, C=C, max_iter = num_iterations, solver=\"lbfgs\")\n",
        "            measures =  classify(model, trainx, trainy, testx, testy)\n",
        "            bestModels = updateLogisticRegression(measures, bestModels, model, C, penalty)\n",
        "\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU7MZ9M6iQe5"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xPQfU56iQe6",
        "outputId": "94d1bbf1-e5c0-4b29-98c6-c0b572492b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: LogisticRegression(C=15, max_iter=1000), measure: 0.7510460251046025, hyperparameters: C: 15, penalty: l2, \n",
            "\n",
            "f1_macro: model: LogisticRegression(C=6, max_iter=1000), measure: 0.5536878326233475, hyperparameters: C: 6, penalty: l2, \n",
            "\n",
            "f1_weighted: model: LogisticRegression(C=15, max_iter=1000), measure: 0.727310899351831, hyperparameters: C: 15, penalty: l2, \n",
            "\n",
            "mcc: model: LogisticRegression(C=15, max_iter=1000), measure: 0.6829000610929165, hyperparameters: C: 15, penalty: l2, \n",
            "\n",
            "gmean: model: LogisticRegression(C=15, max_iter=1000), measure: 0.7510460251046024, hyperparameters: C: 15, penalty: l2, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "regularizations = ['l2', 'none']\n",
        "cValues = [0.0001, 0.001, 0.01,0.05, 0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20]\n",
        "iterations = 1000\n",
        "\n",
        "models = bestLogisticRegression(X_train, Y_train, X_val, Y_val, regularizations, cValues, iterations)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGo4nFCriQe6"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joZrajkriQe6",
        "outputId": "c81a857a-e8a0-403b-b3e2-cbaa95a652c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 75.1%\n",
            "accuracy on validation set= 75.1%\n",
            "accuracy on test set= 74.09%\n",
            "\n",
            "f1_macro on Training set= 56.56%\n",
            "f1_macro on validation set= 55.37%\n",
            "f1_macro on test set= 54.72%\n",
            "\n",
            "f1_weighted on Training set= 72.5%\n",
            "f1_weighted on validation set= 72.73%\n",
            "f1_weighted on test set= 71.48%\n",
            "\n",
            "mcc on Training set= 68.29%\n",
            "mcc on validation set= 68.29%\n",
            "mcc on test set= 66.97%\n",
            "\n",
            "gmean on Training set= 75.1%\n",
            "gmean on validation set= 75.1%\n",
            "gmean on test set= 74.09%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJX6rJtQiQe7"
      },
      "source": [
        "### **2-SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "Opx4UOepiQe7"
      },
      "outputs": [],
      "source": [
        "def initializeSVM():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"kernel\":\"\",\n",
        "                \"C\":0,\n",
        "                \"degree\":None,\n",
        "                \"coef\":None\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"kernel\":\"\",\n",
        "                \"C\":0,\n",
        "                \"degree\":None,\n",
        "                \"coef\":None\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"kernel\":\"\",\n",
        "                \"C\":0,\n",
        "                \"degree\":None,\n",
        "                \"coef\":None\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"kernel\":\"\",\n",
        "                \"C\":0,\n",
        "                \"degree\":None,\n",
        "                \"coef\":None\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"kernel\":\"\",\n",
        "                \"C\":0,\n",
        "                \"degree\":None,\n",
        "                \"coef\":None\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "\n",
        "def updateSVM(measures, bestModels, model, C, kernel, degree=None, coefficient=None):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"C\"] = C\n",
        "            bestModels[measureType][\"hyperparameters\"][\"kernel\"] = kernel\n",
        "            if degree is not None:\n",
        "                bestModels[measureType][\"hyperparameters\"][\"degree\"] = degree\n",
        "            if coefficient is not None:\n",
        "                bestModels[measureType][\"hyperparameters\"][\"coef\"] = coefficient\n",
        "    return bestModels\n",
        "\n",
        "def bestSVM(trainx, trainy, testx, testy, CValues:list, kernels:list, degrees:list=None, coefficients:list=None):\n",
        "    bestModels = initializeSVM()\n",
        "    for C in CValues:\n",
        "        for kernel in kernels:\n",
        "            if kernel == \"sigmoid\":\n",
        "                for coefficient in coefficients:\n",
        "                    model = SVC(C = C, kernel = kernel, coef0 = coefficient)\n",
        "                    measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                    bestModels = updateSVM(measures, bestModels, model, C, kernel, coefficient=coefficient)\n",
        "            elif kernel == \"poly\":\n",
        "                for degree in degrees:\n",
        "                    for coefficient in coefficients:\n",
        "                        model = SVC(C = C, kernel = kernel, degree = degree, coef0=coefficient)\n",
        "                        measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                        bestModels = updateSVM(measures, bestModels, model, C, kernel, degree=degree, coefficient=coefficient)\n",
        "            else:\n",
        "                model = SVC(C = C, kernel = kernel)\n",
        "                measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                bestModels = updateSVM(measures, bestModels, model, C, kernel)\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlzM9OP4iQe7"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyNZonRdiQe8",
        "outputId": "392f54a3-67c6-4c90-ebf2-93d85215442c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: SVC(C=0.1, kernel='linear'), measure: 0.8221757322175732, hyperparameters: kernel: linear, C: 0.1, degree: None, coef: None, \n",
            "\n",
            "f1_macro: model: SVC(C=0.01, kernel='linear'), measure: 0.7187445031746336, hyperparameters: kernel: linear, C: 0.01, degree: None, coef: None, \n",
            "\n",
            "f1_weighted: model: SVC(C=0.1, kernel='linear'), measure: 0.8197784443746438, hyperparameters: kernel: linear, C: 0.1, degree: None, coef: None, \n",
            "\n",
            "mcc: model: SVC(C=0.1, kernel='linear'), measure: 0.7746480699936555, hyperparameters: kernel: linear, C: 0.1, degree: None, coef: None, \n",
            "\n",
            "gmean: model: SVC(C=0.1, kernel='linear'), measure: 0.8221757322175731, hyperparameters: kernel: linear, C: 0.1, degree: None, coef: None, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "kernels = ['linear','sigmoid','rbf','poly']\n",
        "CValues = [0.01, 0.1, 0.5]\n",
        "degrees = [2,3,4]\n",
        "coefficients = [1]\n",
        "\n",
        "models = bestSVM(X_train, Y_train, X_val, Y_val, CValues, kernels, degrees, coefficients)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLsv7loCiQe8"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F_U8RViiQe8",
        "outputId": "32ef8209-622f-4282-dab8-d5271f04d3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 82.4%\n",
            "accuracy on validation set= 82.22%\n",
            "accuracy on test set= 81.5%\n",
            "\n",
            "f1_macro on Training set= 71.99%\n",
            "f1_macro on validation set= 71.87%\n",
            "f1_macro on test set= 68.92%\n",
            "\n",
            "f1_weighted on Training set= 81.97%\n",
            "f1_weighted on validation set= 81.98%\n",
            "f1_weighted on test set= 81.11%\n",
            "\n",
            "mcc on Training set= 77.67%\n",
            "mcc on validation set= 77.46%\n",
            "mcc on test set= 76.53%\n",
            "\n",
            "gmean on Training set= 82.4%\n",
            "gmean on validation set= 82.22%\n",
            "gmean on test set= 81.5%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHKXSZd6iQe9"
      },
      "source": [
        "## **Non-Linear classifiers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfq49rahiQe9"
      },
      "source": [
        "### **1-KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "3kxYMiIKiQe9"
      },
      "outputs": [],
      "source": [
        "def initializeKNN():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"algorithm\":\"\",\n",
        "                \"kRange\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"algorithm\":\"\",\n",
        "                \"kRange\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"algorithm\":\"\",\n",
        "                \"kRange\":0\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"algorithm\":\"\",\n",
        "                \"kRange\":0\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"algorithm\":\"\",\n",
        "                \"kRange\":0\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def updateKNN(measures, bestModels, model, k, algorithm):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"kRange\"] = k\n",
        "            bestModels[measureType][\"hyperparameters\"][\"algorithm\"] = algorithm\n",
        "    return bestModels\n",
        "\n",
        "def bestKNN(trainx, trainy, testx, testy, algorithms:list, kRange:list):\n",
        "    bestModels = initializeKNN()\n",
        "    for algorithm in algorithms:\n",
        "        for k in kRange:\n",
        "            model = KNeighborsClassifier(n_neighbors=k, algorithm = algorithm)\n",
        "            measures =  classify(model, trainx, trainy, testx, testy)\n",
        "            bestModels = updateKNN(measures, bestModels, model, k, algorithm)\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iquwqkLiQe9"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCrRKGLeiQe-",
        "outputId": "27c6ba89-b458-47b3-eae5-f019a37b360c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: KNeighborsClassifier(n_neighbors=3), measure: 0.8096234309623431, hyperparameters: algorithm: auto, kRange: 3, \n",
            "\n",
            "f1_macro: model: KNeighborsClassifier(n_neighbors=7), measure: 0.7506002778669648, hyperparameters: algorithm: auto, kRange: 7, \n",
            "\n",
            "f1_weighted: model: KNeighborsClassifier(n_neighbors=4), measure: 0.8042937444687809, hyperparameters: algorithm: auto, kRange: 4, \n",
            "\n",
            "mcc: model: KNeighborsClassifier(n_neighbors=3), measure: 0.7601134803907709, hyperparameters: algorithm: auto, kRange: 3, \n",
            "\n",
            "gmean: model: KNeighborsClassifier(n_neighbors=3), measure: 0.8096234309623431, hyperparameters: algorithm: auto, kRange: 3, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "algorithms = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "kRange = [1,2,3,4,5,6,7,8,9,10,12,15]\n",
        "\n",
        "models = bestKNN(X_train, Y_train, X_val, Y_val, algorithms, kRange)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0euDtVCsiQe-"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2hmgbiAiQe-",
        "outputId": "bfc3210c-7d0b-45bc-cdf7-2d8fadf8aef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 89.89%\n",
            "accuracy on validation set= 80.96%\n",
            "accuracy on test set= 80.36%\n",
            "\n",
            "f1_macro on Training set= 79.81%\n",
            "f1_macro on validation set= 75.06%\n",
            "f1_macro on test set= 73.28%\n",
            "\n",
            "f1_weighted on Training set= 88.73%\n",
            "f1_weighted on validation set= 80.43%\n",
            "f1_weighted on test set= 80.11%\n",
            "\n",
            "mcc on Training set= 87.28%\n",
            "mcc on validation set= 76.01%\n",
            "mcc on test set= 75.2%\n",
            "\n",
            "gmean on Training set= 89.89%\n",
            "gmean on validation set= 80.96%\n",
            "gmean on test set= 80.36%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaATm2vtiQe_"
      },
      "source": [
        "### **2-Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "TK2J1c0biQe_"
      },
      "outputs": [],
      "source": [
        "def initializeNeuralNetwork():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"numOfHiddenLayers\":0,\n",
        "                \"activation\":\"\",\n",
        "                \"tol\":0,\n",
        "                \"learning_rate\":0,\n",
        "                \"max_iterations\":0,\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"numOfHiddenLayers\":0,\n",
        "                \"activation\":\"\",\n",
        "                \"tol\":0,\n",
        "                \"learning_rate\":0,\n",
        "                \"max_iterations\":0,\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"numOfHiddenLayers\":0,\n",
        "                \"activation\":\"\",\n",
        "                \"tol\":0,\n",
        "                \"learning_rate\":0,\n",
        "                \"max_iterations\":0,\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"numOfHiddenLayers\":0,\n",
        "                \"activation\":\"\",\n",
        "                \"tol\":0,\n",
        "                \"learning_rate\":0,\n",
        "                \"max_iterations\":0,\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"numOfHiddenLayers\":0,\n",
        "                \"activation\":\"\",\n",
        "                \"tol\":0,\n",
        "                \"learning_rate\":0,\n",
        "                \"max_iterations\":0,\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def updateDecisionTree(measures, bestModels, model, hiddenLayers, activation, tol, learningRate, max_iteration):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"numOfHiddenLayers\"] = hiddenLayers\n",
        "            bestModels[measureType][\"hyperparameters\"][\"activation\"] = activation\n",
        "            bestModels[measureType][\"hyperparameters\"][\"tol\"] = tol\n",
        "            bestModels[measureType][\"hyperparameters\"][\"learning_rate\"] = learningRate\n",
        "            bestModels[measureType][\"hyperparameters\"][\"max_iterations\"] = max_iteration\n",
        "    return bestModels\n",
        "\n",
        "def bestNeuralNetwork(trainx, trainy, testx, testy, numberOfHiddenLayers:list, activations:list, tols:list, learningRates:list, max_iterations:list):\n",
        "    bestModels = initializeNeuralNetwork()\n",
        "    for activation in activations:\n",
        "        for tol in tols:\n",
        "            for hiddenLayers in numberOfHiddenLayers:\n",
        "                for learningRate in learningRates:\n",
        "                    for max_iteration in max_iterations:\n",
        "                        model = MLPClassifier(hidden_layer_sizes = hiddenLayers, learning_rate = \"constant\", learning_rate_init = learningRate, max_iter = max_iteration, tol = tol)\n",
        "                        measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                        bestModels = updateDecisionTree(measures, bestModels, model, hiddenLayers, activation, tol, learningRate, max_iteration)\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgXD4I1UiQe_"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_8oVnaYiQe_",
        "outputId": "b1704fe2-986a-4145-aebf-6b53c31aa0a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.005, max_iter=1000,\n",
            "              tol=1e-05), measure: 0.7311715481171548, hyperparameters: numOfHiddenLayers: 3, activation: relu, tol: 1e-05, learning_rate: 0.005, max_iterations: 1000, \n",
            "\n",
            "f1_macro: model: MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.005, max_iter=1000,\n",
            "              tol=1e-05), measure: 0.42630171218522817, hyperparameters: numOfHiddenLayers: 3, activation: relu, tol: 1e-05, learning_rate: 0.005, max_iterations: 1000, \n",
            "\n",
            "f1_weighted: model: MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.005, max_iter=1000,\n",
            "              tol=1e-05), measure: 0.6771736362683463, hyperparameters: numOfHiddenLayers: 3, activation: relu, tol: 1e-05, learning_rate: 0.005, max_iterations: 1000, \n",
            "\n",
            "mcc: model: MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.005, max_iter=1000,\n",
            "              tol=1e-05), measure: 0.6623565914699655, hyperparameters: numOfHiddenLayers: 3, activation: relu, tol: 1e-05, learning_rate: 0.005, max_iterations: 1000, \n",
            "\n",
            "gmean: model: MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.005, max_iter=1000,\n",
            "              tol=1e-05), measure: 0.7311715481171548, hyperparameters: numOfHiddenLayers: 3, activation: relu, tol: 1e-05, learning_rate: 0.005, max_iterations: 1000, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "numOfHiddenLayers = [1,2,3]\n",
        "activations = [\"relu\", \"logistic\", \"tanh\"]\n",
        "tols = [1e-4, 1e-5]\n",
        "learning_rates = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
        "max_iterations = [100,1000,10000]\n",
        "\n",
        "models = bestNeuralNetwork(X_train, Y_train, X_val, Y_val, numOfHiddenLayers, activations, tols, learning_rates, max_iterations)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEa4eq76iQfA"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLAypomuiQfA",
        "outputId": "8bb34751-6eaa-4257-d4b0-7c033160fda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 72.63%\n",
            "accuracy on validation set= 73.12%\n",
            "accuracy on test set= 71.37%\n",
            "\n",
            "f1_macro on Training set= 42.21%\n",
            "f1_macro on validation set= 42.63%\n",
            "f1_macro on test set= 41.37%\n",
            "\n",
            "f1_weighted on Training set= 67.07%\n",
            "f1_weighted on validation set= 67.72%\n",
            "f1_weighted on test set= 65.85%\n",
            "\n",
            "mcc on Training set= 65.76%\n",
            "mcc on validation set= 66.24%\n",
            "mcc on test set= 64.02%\n",
            "\n",
            "gmean on Training set= 72.63%\n",
            "gmean on validation set= 73.12%\n",
            "gmean on test set= 71.37%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMpzTbZiQfA"
      },
      "source": [
        "### **3-Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "4CESNktfiQfA"
      },
      "outputs": [],
      "source": [
        "def initializeDecisionTree():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"splitter\":\"\",\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"splitter\":\"\",\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"splitter\":\"\",\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"splitter\":\"\",\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"splitter\":\"\",\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "\n",
        "    }\n",
        "\n",
        "def updateDecisionTree(measures, bestModels, model, criterion, splitter, max_depth):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"criterion\"] = criterion\n",
        "            bestModels[measureType][\"hyperparameters\"][\"splitter\"] = splitter\n",
        "            bestModels[measureType][\"hyperparameters\"][\"max_depth\"] = max_depth\n",
        "    return bestModels\n",
        "\n",
        "def bestDecisionTree(trainx, trainy, testx, testy, criterions:list, splitters:list, max_depths:list):\n",
        "    bestModels = initializeDecisionTree()\n",
        "    for criterion in criterions:\n",
        "        for splitter in splitters:\n",
        "            for max_depth in max_depths:\n",
        "                model = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth)\n",
        "                measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                bestModels = updateDecisionTree(measures, bestModels, model, criterion, splitter, max_depth)\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAX7FJsHiQfA"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r3kkAcGiQfA",
        "outputId": "588d61b1-9959-490d-bca8-7244c545b607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: DecisionTreeClassifier(criterion='entropy', max_depth=2000, splitter='random'), measure: 0.9027196652719666, hyperparameters: criterion: entropy, splitter: random, max_depth: 2000, \n",
            "\n",
            "f1_macro: model: DecisionTreeClassifier(max_depth=200, splitter='random'), measure: 0.8526030467353168, hyperparameters: criterion: gini, splitter: random, max_depth: 200, \n",
            "\n",
            "f1_weighted: model: DecisionTreeClassifier(criterion='entropy', max_depth=2000, splitter='random'), measure: 0.9029755542685424, hyperparameters: criterion: entropy, splitter: random, max_depth: 2000, \n",
            "\n",
            "mcc: model: DecisionTreeClassifier(criterion='entropy', max_depth=2000, splitter='random'), measure: 0.8774138645824169, hyperparameters: criterion: entropy, splitter: random, max_depth: 2000, \n",
            "\n",
            "gmean: model: DecisionTreeClassifier(criterion='entropy', max_depth=2000, splitter='random'), measure: 0.9027196652719665, hyperparameters: criterion: entropy, splitter: random, max_depth: 2000, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "criterions = [\"gini\",\"entropy\"]\n",
        "splitters = [\"best\",\"random\"]\n",
        "max_depths = [None, 100, 200, 500, 1000, 2000]\n",
        "\n",
        "models = bestDecisionTree(X_train, Y_train, X_val, Y_val, criterions, splitters, max_depths)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6jmNVbTiQfA"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGZhEzXniQfA",
        "outputId": "3d66740a-4bb4-4563-a03c-ee0d156e7ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 100.0%\n",
            "accuracy on validation set= 90.27%\n",
            "accuracy on test set= 89.13%\n",
            "\n",
            "f1_macro on Training set= 100.0%\n",
            "f1_macro on validation set= 85.26%\n",
            "f1_macro on test set= 84.7%\n",
            "\n",
            "f1_weighted on Training set= 100.0%\n",
            "f1_weighted on validation set= 90.3%\n",
            "f1_weighted on test set= 89.08%\n",
            "\n",
            "mcc on Training set= 100.0%\n",
            "mcc on validation set= 87.74%\n",
            "mcc on test set= 86.28%\n",
            "\n",
            "gmean on Training set= 100.0%\n",
            "gmean on validation set= 90.27%\n",
            "gmean on test set= 89.13%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj_aHs7kiQfB"
      },
      "source": [
        "## **Ensembel Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L_teDqliQfB"
      },
      "source": [
        "### **1-Bagging**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "zhH4rPCuiQfB"
      },
      "outputs": [],
      "source": [
        "def initializeBagging():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"max_features\":0,\n",
        "                \"estimators\":0,\n",
        "                \"oob_score\":False,\n",
        "                \"max_samples\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"max_features\":0,\n",
        "                \"estimators\":0,\n",
        "                \"oob_score\":False,\n",
        "                \"max_samples\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"max_features\":0,\n",
        "                \"estimators\":0,\n",
        "                \"oob_score\":False,\n",
        "                \"max_samples\":0\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"max_features\":0,\n",
        "                \"estimators\":0,\n",
        "                \"oob_score\":False,\n",
        "                \"max_samples\":0\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"max_features\":0,\n",
        "                \"estimators\":0,\n",
        "                \"oob_score\":False,\n",
        "                \"max_samples\":0\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def updateBagging(measures, bestModels, model, estimators, max_samples, max_features, oob_score):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"max_features\"] = max_features\n",
        "            bestModels[measureType][\"hyperparameters\"][\"estimators\"] = estimators\n",
        "            bestModels[measureType][\"hyperparameters\"][\"max_samples\"] = max_samples\n",
        "            bestModels[measureType][\"hyperparameters\"][\"oob_score\"] = oob_score\n",
        "    return bestModels\n",
        "\n",
        "def bestBagging(trainx, trainy, testx, testy, estimators:list, max_samples_range:list, max_features_range:list, oob_scores:list):\n",
        "    bestModels = initializeBagging()\n",
        "    for max_samples in max_samples_range:\n",
        "        for max_features in max_features_range:\n",
        "            for estimator in estimators:\n",
        "                for oob_score in oob_scores:\n",
        "                    model = BaggingClassifier(n_estimators=estimator, max_samples=max_samples, max_features=max_features, oob_score = oob_score)\n",
        "                    measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                    bestModels = updateBagging(measures, bestModels, model, estimator, max_samples, max_features, oob_scores)\n",
        "    return bestModels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiroeqmZiQfB"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meJxNarhiQfB",
        "outputId": "74bfa0d0-dedf-4050-f180-1aa1eaff1ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: BaggingClassifier(max_features=15, max_samples=2000, n_estimators=80,\n",
            "                  oob_score=200), measure: 0.9236401673640168, hyperparameters: max_features: 15, estimators: 80, oob_score: [None, 100, 200, 500, 1000, 2000], max_samples: 2000, \n",
            "\n",
            "f1_macro: model: BaggingClassifier(max_features=20, max_samples=2000, n_estimators=150,\n",
            "                  oob_score=100), measure: 0.886206507777847, hyperparameters: max_features: 20, estimators: 150, oob_score: [None, 100, 200, 500, 1000, 2000], max_samples: 2000, \n",
            "\n",
            "f1_weighted: model: BaggingClassifier(max_features=15, max_samples=2000, n_estimators=80,\n",
            "                  oob_score=200), measure: 0.9218921471896853, hyperparameters: max_features: 15, estimators: 80, oob_score: [None, 100, 200, 500, 1000, 2000], max_samples: 2000, \n",
            "\n",
            "mcc: model: BaggingClassifier(max_features=15, max_samples=2000, n_estimators=80,\n",
            "                  oob_score=200), measure: 0.9033254369778683, hyperparameters: max_features: 15, estimators: 80, oob_score: [None, 100, 200, 500, 1000, 2000], max_samples: 2000, \n",
            "\n",
            "gmean: model: BaggingClassifier(max_features=15, max_samples=2000, n_estimators=80,\n",
            "                  oob_score=200), measure: 0.9236401673640168, hyperparameters: max_features: 15, estimators: 80, oob_score: [None, 100, 200, 500, 1000, 2000], max_samples: 2000, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "estimators = [50,70,80,90,100,110,120,150,200]\n",
        "oob_scores = [True, False]\n",
        "max_samples = [1, 100, 150, 200, 500, 1000, 2000]\n",
        "max_features = [1,2,3,4,5,10,15,20]\n",
        "\n",
        "models = bestBagging(X_train, Y_train, X_val, Y_val, estimators, max_samples, max_features, max_depths)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1J_XWiviQfC"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tATiiTUHiQfC",
        "outputId": "91eb66a6-7ddb-4bbb-e2cc-6d69cfed63b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 98.5%\n",
            "accuracy on validation set= 92.36%\n",
            "accuracy on test set= 93.42%\n",
            "\n",
            "f1_macro on Training set= 96.93%\n",
            "f1_macro on validation set= 88.62%\n",
            "f1_macro on test set= 88.62%\n",
            "\n",
            "f1_weighted on Training set= 98.49%\n",
            "f1_weighted on validation set= 92.19%\n",
            "f1_weighted on test set= 93.29%\n",
            "\n",
            "mcc on Training set= 98.1%\n",
            "mcc on validation set= 90.33%\n",
            "mcc on test set= 91.67%\n",
            "\n",
            "gmean on Training set= 98.5%\n",
            "gmean on validation set= 92.36%\n",
            "gmean on test set= 93.42%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0RomvNviQfC"
      },
      "source": [
        "### **2-Adaboost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "z3k3lzVEiQfD"
      },
      "outputs": [],
      "source": [
        "def initializeAdaboost():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"estimator\":0,\n",
        "                \"alpha\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"estimator\":0,\n",
        "                \"alpha\":0\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"algorithm\":\"\",\n",
        "                \"alpha\":0\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"estimator\":0,\n",
        "                \"alpha\":0\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"estimator\":0,\n",
        "                \"alpha\":0\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def updateAdaboost(measures, bestModels, model, estimator, alpha):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"estimator\"] = estimator\n",
        "            bestModels[measureType][\"hyperparameters\"][\"alpha\"] = alpha\n",
        "    return bestModels\n",
        "\n",
        "def bestAdaboost(trainx, trainy, testx, testy, estimators:list, alphas:list):\n",
        "    bestModels = initializeAdaboost()\n",
        "    for estimator in estimators:\n",
        "        for alpha in alphas:\n",
        "            model = AdaBoostClassifier(n_estimators=estimator, learning_rate=alpha)\n",
        "            measures =  classify(model, trainx, trainy, testx, testy)\n",
        "            bestModels = updateAdaboost(measures, bestModels, model, estimator, alpha)\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsl-mWAXiQfD"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg2JZ1eeiQfD",
        "outputId": "be28ba13-39b7-491c-be67-248234ae4f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: AdaBoostClassifier(learning_rate=0.001), measure: 0.6684100418410042, hyperparameters: estimator: 50, alpha: 0.001, \n",
            "\n",
            "f1_macro: model: AdaBoostClassifier(learning_rate=2, n_estimators=70), measure: 0.42114567608455467, hyperparameters: estimator: 70, alpha: 2, \n",
            "\n",
            "f1_weighted: model: AdaBoostClassifier(learning_rate=0.001), measure: 0.551787142294103, hyperparameters: algorithm: , alpha: 0.001, estimator: 50, \n",
            "\n",
            "mcc: model: AdaBoostClassifier(learning_rate=0.001), measure: 0.599289551634668, hyperparameters: estimator: 50, alpha: 0.001, \n",
            "\n",
            "gmean: model: AdaBoostClassifier(learning_rate=0.001), measure: 0.6684100418410043, hyperparameters: estimator: 50, alpha: 0.001, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "alphas = [0.001,0.01,0.1,0.25,0.5,0.75,1,1.5,2]\n",
        "estimators = [50,60,65,70,75,80,90,100]\n",
        "\n",
        "models = bestAdaboost(X_train, Y_train, X_val, Y_val, estimators, alphas)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnZ6jn3eiQfD"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xk8Tu6EiQfE",
        "outputId": "a85424d8-4987-49a5-b09b-a56a35530595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 67.09%\n",
            "accuracy on validation set= 66.84%\n",
            "accuracy on test set= 67.29%\n",
            "\n",
            "f1_macro on Training set= 41.2%\n",
            "f1_macro on validation set= 42.11%\n",
            "f1_macro on test set= 38.91%\n",
            "\n",
            "f1_weighted on Training set= 55.42%\n",
            "f1_weighted on validation set= 55.18%\n",
            "f1_weighted on test set= 55.67%\n",
            "\n",
            "mcc on Training set= 60.3%\n",
            "mcc on validation set= 59.93%\n",
            "mcc on test set= 60.62%\n",
            "\n",
            "gmean on Training set= 67.09%\n",
            "gmean on validation set= 66.84%\n",
            "gmean on test set= 67.29%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h29GoEfdiQfE"
      },
      "source": [
        "### **3-Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "vKRUXDa-iQfE"
      },
      "outputs": [],
      "source": [
        "def initializeRandomForest():\n",
        "    return{\n",
        "        \"accuracy\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"estimators\":0,\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"f1_macro\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"estimators\":0,\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"f1_weighted\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"estimators\":0,\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"mcc\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"estimators\":0,\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        },\n",
        "        \"gmean\":{\n",
        "            \"model\":None,\n",
        "            \"measure\":0,\n",
        "            \"hyperparameters\":{\n",
        "                \"criterion\":\"\",\n",
        "                \"estimators\":0,\n",
        "                \"max_depth\":0,\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def updateRandomForest(measures, bestModels, model, criterion, estimators, max_depth):\n",
        "    for measureType in measures:\n",
        "        if (measures[measureType]> bestModels[measureType][\"measure\"]):\n",
        "            bestModels[measureType][\"measure\"] = measures[measureType]\n",
        "            bestModels[measureType][\"model\"] = model\n",
        "            bestModels[measureType][\"hyperparameters\"][\"criterion\"] = criterion\n",
        "            bestModels[measureType][\"hyperparameters\"][\"estimators\"] = estimators\n",
        "            bestModels[measureType][\"hyperparameters\"][\"max_depth\"] = max_depth\n",
        "    return bestModels\n",
        "\n",
        "def bestRandomForest(trainx, trainy, testx, testy, criterions:list, estimators:list, max_depths:list):\n",
        "    bestModels = initializeRandomForest()\n",
        "    for criterion in criterions:\n",
        "        for estimator in estimators:\n",
        "            for max_depth in max_depths:\n",
        "                model = RandomForestClassifier(criterion=criterion, n_estimators=estimator, max_depth=max_depth)\n",
        "                measures =  classify(model, trainx, trainy, testx, testy)\n",
        "                bestModels = updateRandomForest(measures, bestModels, model, criterion, estimator, max_depth)\n",
        "    return bestModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QZLVO4iQfE"
      },
      "source": [
        "**Training model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ssBUtnLiQfF",
        "outputId": "81b15a4a-6311-4249-f7cb-189c57dfd212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: model: RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=70), measure: 0.9361924686192469, hyperparameters: criterion: entropy, estimators: 70, max_depth: 100, \n",
            "\n",
            "f1_macro: model: RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=50), measure: 0.8950690720086759, hyperparameters: criterion: entropy, estimators: 50, max_depth: 100, \n",
            "\n",
            "f1_weighted: model: RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=70), measure: 0.9349316769139007, hyperparameters: criterion: entropy, estimators: 70, max_depth: 100, \n",
            "\n",
            "mcc: model: RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=70), measure: 0.9192384802989317, hyperparameters: criterion: entropy, estimators: 70, max_depth: 100, \n",
            "\n",
            "gmean: model: RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=70), measure: 0.9361924686192469, hyperparameters: criterion: entropy, estimators: 70, max_depth: 100, \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "criterions = [\"gini\",\"entropy\"]\n",
        "estimators = [50,70,80,90,100,110,120,150,200]\n",
        "max_depths = [None, 100, 200, 500, 1000, 2000]\n",
        "\n",
        "models = bestRandomForest(X_train, Y_train, X_val, Y_val, criterions, estimators, max_depths)\n",
        "printModels(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAFc5XOOiQfF"
      },
      "source": [
        "**Testing model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cALAKTF-iQfF",
        "outputId": "be174b3a-bd55-44af-8ac9-00327b64a4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on Training set= 100.0%\n",
            "accuracy on validation set= 93.62%\n",
            "accuracy on test set= 93.31%\n",
            "\n",
            "f1_macro on Training set= 100.0%\n",
            "f1_macro on validation set= 89.51%\n",
            "f1_macro on test set= 88.5%\n",
            "\n",
            "f1_weighted on Training set= 100.0%\n",
            "f1_weighted on validation set= 93.49%\n",
            "f1_weighted on test set= 93.13%\n",
            "\n",
            "mcc on Training set= 100.0%\n",
            "mcc on validation set= 91.92%\n",
            "mcc on test set= 91.54%\n",
            "\n",
            "gmean on Training set= 100.0%\n",
            "gmean on validation set= 93.62%\n",
            "gmean on test set= 93.31%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "displayResults(models, X_train, Y_train, X_val, Y_val, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FGn-pppRESz"
      },
      "source": [
        "# **Project report**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZw4dU3EDmV4"
      },
      "source": [
        "###best performing classifier was ***Random Forest*** with the following results: **93.31%** on **Accuracy** measure without **Feature Expansion**, and with **Feature Expansion** the results were **93.83%** on **Accuracy** measure, with performance diffrence of **+0.55%**, we decided that the performance increase was not worth the increase in training time of all classifiers.\n",
        "\n",
        "###the results shows that **accuracy** was the best measure for this classifier followed by **Gmean** since it provided much similar results as compared to accuracy.\n",
        "\n",
        "### ***Note***: Random Forest follows Decision Tree's behavior which have slight randomness while splitting data which might change the accuracy slightly with each run.\n",
        "\n",
        "### **Feature Expansion:** might slow the training process depending on the classifier (with a slight improvement on performance).\n",
        "\n",
        "### **Dimensionality Reduction:** it did a great job reducing the features but we decided to disable it since it drops the performance significantly.\n",
        "\n",
        "###**Scaling Data:** we found that the **Standard Scaler** preformed slightly better."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
